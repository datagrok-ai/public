import os
import sys
import logging
import tempfile
from time import time
from numpy.linalg import norm
from concurrent.futures import ThreadPoolExecutor

import torch
import numpy as np
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from flask import Flask, request, jsonify
from flask_cors import CORS
from lightning import pytorch as pl
from lightning.pytorch.accelerators import find_usable_cuda_devices
from io import StringIO

from constants import mean_vectors
from chemprop import data, featurizers, models


app = Flask(__name__)
CORS(app)

logging_level = logging.DEBUG
logging.basicConfig(level=logging_level)

# Global flag to control whether exceptions should be raised or logged
raise_ex_flag = False  # Default is to log exceptions, not raise them

def is_malformed(smiles):
  with tempfile.NamedTemporaryFile(mode='w+', delete=True) as tmp_file:
    stderr_fileno = sys.stderr.fileno()
    stderr_backup = os.dup(stderr_fileno)

    try:
      os.dup2(tmp_file.fileno(), stderr_fileno)
      mol = Chem.MolFromSmiles(smiles)
      os.dup2(stderr_backup, stderr_fileno)
    finally:
      os.close(stderr_backup)
    
    tmp_file.seek(0)
    warning_msg = tmp_file.read().strip()

  if mol is None or warning_msg:
    print(f"Invalid SMILES detected: {smiles}. Warning: {warning_msg}")
    if raise_ex_flag:
      raise ValueError(f"Invalid SMILES string: {smiles}. Warning: {warning_msg}")
    return True

  return False

def convert_to_smiles(molecule):
  if "M  END" in molecule:
    try:
      mol = Chem.MolFromMolBlock(molecule)
      return Chem.MolToSmiles(mol) if mol else ''
    except Exception as e:
      logging.error(f"Error converting molblock to SMILES: {str(e)}")
      if raise_ex_flag:
        raise ValueError("Error converting molblock to SMILES") from e
      return None
  return molecule

def parallel_process_smiles(smis):
  with ThreadPoolExecutor(max_workers=8) as executor:
    valid_smiles = list(executor.map(convert_to_smiles, smis))
  return valid_smiles

def make_chemprop_predictions(df_test, checkpoint_path, batch_size=512):
  # Check for GPU availability
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  # Load the model onto the appropriate device
  mpnn = models.MPNN.load_from_checkpoint(checkpoint_path, map_location=device)

  smis = df_test.iloc[:, 0].tolist()
  valid_indices = [i for i, smi in enumerate(smis) if not is_malformed(smi) and smi != '']
  valid_smiles = [smis[i] for i in valid_indices]
  invalid_indices = [i for i in range(len(smis)) if i not in valid_indices]

  if not valid_smiles:
    return np.array([""] * len(smis), dtype=object)

  test_data = [data.MoleculeDatapoint.from_smi(smi) for smi in valid_smiles]
  featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()
  test_dset = data.MoleculeDataset(test_data, featurizer=featurizer)

  test_loader = data.build_dataloader(
    test_dset,
    shuffle=False,
    batch_size=batch_size
  )

  logging.debug('Check GPU availability')
  logging.debug(f"CUDA available: {torch.cuda.is_available()}")

  if torch.cuda.is_available():
    logging.debug(f"Usable CUDA devices: {find_usable_cuda_devices(1)}")
  else:
    logging.debug("No usable CUDA devices found. Using CPU.")

  logging.debug(f'Model device: {next(mpnn.parameters()).device}')

  with torch.inference_mode():
    trainer = pl.Trainer(
      logger=True,
      enable_progress_bar=True,
      accelerator="gpu" if torch.cuda.is_available() else "cpu",  # Use GPU if available, else CPU
      devices=1,
      precision=16 if torch.cuda.is_available() else 32   # Enable mixed precision if using GPU, otherwise default
    )
    test_preds = trainer.predict(mpnn, test_loader)

  test_preds = [pred.item() for batch in test_preds for pred in batch]
  for index in invalid_indices:
    test_preds.insert(index, "")

  return np.array(test_preds, dtype=object)

def generate_fingerprint(smiles):
  mol = Chem.MolFromSmiles(smiles)
  if mol:
    fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)
    return list(map(int, fingerprint))
  return None

def calculate_similarity(mean_vector, fingerprint):
  return np.dot(mean_vector, fingerprint) / (norm(mean_vector) * norm(fingerprint))

def calculate_chemprop_probability(smiles_list, model):
  mean_vector = mean_vectors[model]
  return [
    calculate_similarity(mean_vector, generate_fingerprint(smiles))
    if generate_fingerprint(smiles) else 0.0
    for smiles in smiles_list
  ]

def find_model(model):
  files_in_dir = os.listdir()
  model_name = next(
    (file for file in files_in_dir if model.lower() in file.lower() and file.lower().endswith('.ckpt')),
    None
  )
  return model_name

def predict_for_model(model, df_test, add_probability):
  model_name = find_model(model)
  if not model_name:
    raise ValueError(f"No matching model extension found for model '{model}'")

  start = time()
  predictions = make_chemprop_predictions(df_test, model_name)
  logging.debug(f'Chemprop prediction for {model} took {time() - start}')
  df = pd.DataFrame(predictions, columns=[model])
  if add_probability:
    probabilities = calculate_chemprop_probability(df_test.iloc[:, 0].tolist(), model)
    df[f'Y_{model}_probability'] = probabilities
  return df

def predict(data, models, add_probability, batch_size=1000):
  models_res = models.split(",")
  result_dfs = []

  df_test = pd.read_csv(
    StringIO(data.decode('utf-8')),
    skip_blank_lines=False,
    keep_default_na=False,
    na_values=['']
  )
  df_test = df_test.fillna('')
  df_test.iloc[:, 0] = parallel_process_smiles(df_test.iloc[:, 0].tolist())

  for model in models_res:
    model_results = []
    for j in range(0, len(df_test), batch_size):
      batch_df = df_test.iloc[j:j + batch_size]
      result_df = predict_for_model(model, batch_df, add_probability)
      model_results.append(result_df)
    model_result_df = pd.concat(model_results, axis=0, ignore_index=True)
    result_dfs.append(model_result_df)

  final_df = pd.concat(result_dfs, axis=1).loc[:, ~pd.concat(result_dfs, axis=1).columns.duplicated()]
  return final_df.to_csv(index=False)

@app.errorhandler(Exception)
def handle_exception(e):
  logging.error(f"Unhandled Exception: {str(e)}")
  response = {
    "success": False,
    "error": str(e),
    "result": None
  }
  return jsonify(response), 500

@app.route('/predict', methods=['POST'])
def admetica_predict():
  global raise_ex_flag
  
  try:
    raise_ex_flag = request.args.get('raiseException', 'false').lower() == 'true'
    raw_data = request.data
    models = request.args.get('models')
    add_probability = False
    start = time()
    response_data = predict(raw_data, models, add_probability)
    logging.debug(f'Time required: {time() - start}')
    
    return jsonify({
      "success": True,
      "error": None,
      "result": response_data
    }), 200

  except Exception as e:
    logging.error(f"Error in prediction: {str(e)}")
    return jsonify({
      "success": False,
      "error": str(e),
      "result": None
    }), 500

if __name__ == '__main__':
  app.run(host='0.0.0.0', port=8000, debug=False)